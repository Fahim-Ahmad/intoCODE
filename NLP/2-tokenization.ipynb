{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Tokenization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main topics:\n",
    "\n",
    "        - dividing a text into sentences\n",
    "        - tokenize a sentence into words\n",
    "        - extracting most common words\n",
    "        - finding out to which class belong each word (POS tagging)\n",
    "        - extracting words thaat belong to a particular class. i.e., all nouns, verbs, adjectives, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using **nltk** (natural language toolkit) package from Stanford University. It is included in most pythoon distributions.\n",
    "\n",
    "        - nltk.sent_tokenize(text, language='...') # takes a text as input and divides it into sentences\n",
    "        - nltk.word_tokenize(sentence, language='...') # takes a sentence as input and tokenizes it into words\n",
    "        - stopwords = nltk.corpus.stopwords.words('english') # generate list of stopwords\n",
    "        - nltk.pos_tag(tokens) # takes list of words / tokens as input and adds the part of speech (POS) for eacch word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk # install nltk\n",
    "# nltk.download() # A window should now be opened. Select anything from the NLTK book to install.\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences = 34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nI follow the Moskva.',\n",
       " 'Down to Gorky Park.',\n",
       " 'Listening to the wind of change.',\n",
       " 'An august summer night.',\n",
       " 'The world is closing in.',\n",
       " 'Did you ever think.',\n",
       " 'That we could be so close, like brothers.',\n",
       " \"The future's in the air.\",\n",
       " 'I can feel it everywhere.',\n",
       " 'Blowing with the wind of change.',\n",
       " 'Take me to the magic of the moment.',\n",
       " 'On a glory night.',\n",
       " 'Where the children of tomorrow dream away.',\n",
       " 'In the wind of change.',\n",
       " 'Walking down the street.',\n",
       " 'Distant memories.',\n",
       " 'Are buried in the past forever.',\n",
       " 'I follow the Moskva.',\n",
       " 'Down to Gorky Park.',\n",
       " 'Listening to the wind of change.',\n",
       " 'Take me to the magic of the moment On a glory night.',\n",
       " 'Where the children of tomorrow share their dreams.',\n",
       " 'With you and me.',\n",
       " 'Take me to the magic of the moment.',\n",
       " 'On a glory night.',\n",
       " 'Where the children of tomorrow dream away.',\n",
       " 'In the wind of change.',\n",
       " 'The wind of change.',\n",
       " 'Blows straight into the face of time.',\n",
       " 'Like a stormwind that will.',\n",
       " 'ring the freedom bell.',\n",
       " 'For peace of mind.',\n",
       " 'Let your balalaika sing.',\n",
       " 'What my guitar wants to say.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide below text into sentences\n",
    "\n",
    "text = \"\"\"\n",
    "I follow the Moskva.\n",
    "Down to Gorky Park.\n",
    "Listening to the wind of change.\n",
    "An august summer night.\n",
    "\n",
    "The world is closing in.\n",
    "Did you ever think.\n",
    "That we could be so close, like brothers.\n",
    "The future's in the air.\n",
    "I can feel it everywhere.\n",
    "Blowing with the wind of change.\n",
    "\n",
    "Take me to the magic of the moment.\n",
    "On a glory night.\n",
    "Where the children of tomorrow dream away.\n",
    "In the wind of change.\n",
    "\n",
    "Walking down the street.\n",
    "Distant memories.\n",
    "Are buried in the past forever.\n",
    "I follow the Moskva.\n",
    "Down to Gorky Park.\n",
    "Listening to the wind of change.\n",
    "\n",
    "Take me to the magic of the moment On a glory night.\n",
    "Where the children of tomorrow share their dreams.\n",
    "With you and me.\n",
    "Take me to the magic of the moment.\n",
    "On a glory night.\n",
    "Where the children of tomorrow dream away.\n",
    "In the wind of change.\n",
    "\n",
    "The wind of change.\n",
    "Blows straight into the face of time.\n",
    "Like a stormwind that will.\n",
    "ring the freedom bell.\n",
    "For peace of mind.\n",
    "Let your balalaika sing.\n",
    "What my guitar wants to say.\n",
    "\"\"\"\n",
    "\n",
    "sentences = nltk.sent_tokenize(text, language = 'english')\n",
    "print('number of sentences =', len(sentences))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'Moskva',\n",
       " '.',\n",
       " 'Down',\n",
       " 'to',\n",
       " 'Gorky',\n",
       " 'Park',\n",
       " '.',\n",
       " 'Listening',\n",
       " 'to',\n",
       " 'the',\n",
       " 'wind',\n",
       " 'of',\n",
       " 'change',\n",
       " '.',\n",
       " 'An',\n",
       " 'august',\n",
       " 'summer',\n",
       " 'night',\n",
       " '.',\n",
       " 'The',\n",
       " 'world',\n",
       " 'is',\n",
       " 'closing',\n",
       " 'in',\n",
       " '.',\n",
       " 'Did',\n",
       " 'you',\n",
       " 'ever',\n",
       " 'think',\n",
       " '.',\n",
       " 'That',\n",
       " 'we',\n",
       " 'could',\n",
       " 'be',\n",
       " 'so',\n",
       " 'close',\n",
       " ',',\n",
       " 'like',\n",
       " 'brothers',\n",
       " '.',\n",
       " 'The',\n",
       " 'future',\n",
       " \"'s\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'air',\n",
       " '.',\n",
       " 'I',\n",
       " 'can',\n",
       " 'feel',\n",
       " 'it',\n",
       " 'everywhere',\n",
       " '.',\n",
       " 'Blowing',\n",
       " 'with',\n",
       " 'the',\n",
       " 'wind',\n",
       " 'of',\n",
       " 'change',\n",
       " '.',\n",
       " 'Take',\n",
       " 'me',\n",
       " 'to',\n",
       " 'the',\n",
       " 'magic',\n",
       " 'of',\n",
       " 'the',\n",
       " 'moment',\n",
       " '.',\n",
       " 'On',\n",
       " 'a',\n",
       " 'glory',\n",
       " 'night',\n",
       " '.',\n",
       " 'Where',\n",
       " 'the',\n",
       " 'children',\n",
       " 'of',\n",
       " 'tomorrow',\n",
       " 'dream',\n",
       " 'away',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'wind',\n",
       " 'of',\n",
       " 'change',\n",
       " '.',\n",
       " 'Walking',\n",
       " 'down',\n",
       " 'the',\n",
       " 'street',\n",
       " '.',\n",
       " 'Distant',\n",
       " 'memories',\n",
       " '.',\n",
       " 'Are',\n",
       " 'buried',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'forever',\n",
       " '.',\n",
       " 'I',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'Moskva',\n",
       " '.',\n",
       " 'Down',\n",
       " 'to',\n",
       " 'Gorky',\n",
       " 'Park',\n",
       " '.',\n",
       " 'Listening',\n",
       " 'to',\n",
       " 'the',\n",
       " 'wind',\n",
       " 'of',\n",
       " 'change',\n",
       " '.',\n",
       " 'Take',\n",
       " 'me',\n",
       " 'to',\n",
       " 'the',\n",
       " 'magic',\n",
       " 'of',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'On',\n",
       " 'a',\n",
       " 'glory',\n",
       " 'night',\n",
       " '.',\n",
       " 'Where',\n",
       " 'the',\n",
       " 'children',\n",
       " 'of',\n",
       " 'tomorrow',\n",
       " 'share',\n",
       " 'their',\n",
       " 'dreams',\n",
       " '.',\n",
       " 'With',\n",
       " 'you',\n",
       " 'and',\n",
       " 'me',\n",
       " '.',\n",
       " 'Take',\n",
       " 'me',\n",
       " 'to',\n",
       " 'the',\n",
       " 'magic',\n",
       " 'of',\n",
       " 'the',\n",
       " 'moment',\n",
       " '.',\n",
       " 'On',\n",
       " 'a',\n",
       " 'glory',\n",
       " 'night',\n",
       " '.',\n",
       " 'Where',\n",
       " 'the',\n",
       " 'children',\n",
       " 'of',\n",
       " 'tomorrow',\n",
       " 'dream',\n",
       " 'away',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'wind',\n",
       " 'of',\n",
       " 'change',\n",
       " '.',\n",
       " 'The',\n",
       " 'wind',\n",
       " 'of',\n",
       " 'change',\n",
       " '.',\n",
       " 'Blows',\n",
       " 'straight',\n",
       " 'into',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'time',\n",
       " '.',\n",
       " 'Like',\n",
       " 'a',\n",
       " 'stormwind',\n",
       " 'that',\n",
       " 'will',\n",
       " '.',\n",
       " 'ring',\n",
       " 'the',\n",
       " 'freedom',\n",
       " 'bell',\n",
       " '.',\n",
       " 'For',\n",
       " 'peace',\n",
       " 'of',\n",
       " 'mind',\n",
       " '.',\n",
       " 'Let',\n",
       " 'your',\n",
       " 'balalaika',\n",
       " 'sing',\n",
       " '.',\n",
       " 'What',\n",
       " 'my',\n",
       " 'guitar',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'say',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now tokenize each sentence into the words\n",
    "\n",
    "tokens = [nltk.word_tokenize(e, language = 'english') for e in sentences]\n",
    "tokens = [e for e in tokens for e in e]\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 34),\n",
       " ('the', 21),\n",
       " ('of', 14),\n",
       " ('to', 8),\n",
       " ('wind', 6),\n",
       " ('change', 6),\n",
       " ('night', 4),\n",
       " ('me', 4),\n",
       " ('a', 4),\n",
       " ('I', 3),\n",
       " ('The', 3),\n",
       " ('in', 3),\n",
       " ('Take', 3),\n",
       " ('magic', 3),\n",
       " ('moment', 3),\n",
       " ('On', 3),\n",
       " ('glory', 3),\n",
       " ('Where', 3),\n",
       " ('children', 3),\n",
       " ('tomorrow', 3)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out 10 most common words\n",
    "from collections import Counter\n",
    "\n",
    "tokens_counter = Counter(tokens)\n",
    "tokens_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "punctuations = !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('wind', 6),\n",
       " ('change', 6),\n",
       " ('night', 4),\n",
       " ('Take', 3),\n",
       " ('magic', 3),\n",
       " ('moment', 3),\n",
       " ('glory', 3),\n",
       " ('children', 3),\n",
       " ('tomorrow', 3),\n",
       " ('follow', 2),\n",
       " ('Moskva', 2),\n",
       " ('Gorky', 2),\n",
       " ('Park', 2),\n",
       " ('Listening', 2),\n",
       " ('dream', 2),\n",
       " ('away', 2),\n",
       " ('august', 1),\n",
       " ('summer', 1),\n",
       " ('world', 1),\n",
       " ('closing', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words and punctuation from above tokens and count most common again.\n",
    "\n",
    "import string # to generate list of punttuations\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "punctuations = string.punctuation # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "\n",
    "print('stopwords =', stopwords)\n",
    "print('punctuations =', punctuations)\n",
    "\n",
    "tokens = [e for e in tokens if e.lower() not in stopwords and e not in punctuations]\n",
    "\n",
    "tokens_counter = Counter(tokens)\n",
    "tokens_counter.most_common(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech (POS) Tagging\n",
    "\n",
    "After tokenization of text into the words, one of the common steps in text analysis is to find out to which class each word belongs.\n",
    "\n",
    "For this purpose, I am using the .pos_tag() from nltk package which tags the parts of speech (POS) of each word. for example, the words 'wind' and 'summer' will be tagged as 'NN' which means 'nouns' and the words 'follow' and 'think' will tagged as 'VB' which means 'verb'\n",
    "\n",
    "Below is a list of some of the common POS tags:\n",
    "\n",
    "        - CC - Coordinating conjunction\n",
    "        - CD - Cardinal number\n",
    "        - DT - Determiner\n",
    "        - EX - Existential there\n",
    "        - FW - Foreign word\n",
    "        - IN - Preposition or subordinating conjunction\n",
    "        - JJ - Adjective\n",
    "        - JJR - Adjective, comparative\n",
    "        - JJS - Adjective, superlative\n",
    "        - LS - List item marker\n",
    "        - MD - Modal\n",
    "        - NN - Noun, singular or mass\n",
    "        - NNS - Noun, plural\n",
    "        - NNP - Proper noun, singular\n",
    "        - NNPS - Proper noun, plural\n",
    "        - PDT - Predeterminer\n",
    "        - POS - Possessive ending\n",
    "        - PRP - Personal pronoun\n",
    "        - PRP$ - Possessive pronoun\n",
    "        - RB - Adverb\n",
    "        - RBR - Adverb, comparative\n",
    "        - RBS - Adverb, superlative\n",
    "        - RP - Particle\n",
    "        - TO - to\n",
    "        - UH - Interjection\n",
    "        - VB - Verb, base form\n",
    "        - VBD - Verb, past tense\n",
    "        - VBG - Verb, gerund or present participle\n",
    "        - VBN - Verb, past participle\n",
    "        - VBP - Verb, non-3rd person singular present\n",
    "        - VBZ - Verb, 3rd person singular present\n",
    "        - WDT - Wh-determiner\n",
    "        - WP - Wh-pronoun\n",
    "        - WP$ - Possessive wh-pronoun\n",
    "        - WRB - Wh-adverb\n",
    "\n",
    "use nltk.help.upenn_tagset() for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('follow', 'VB'),\n",
       " ('Moskva', 'NNP'),\n",
       " ('Gorky', 'NNP'),\n",
       " ('Park', 'NNP'),\n",
       " ('Listening', 'NNP'),\n",
       " ('wind', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('august', 'RB'),\n",
       " ('summer', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('world', 'NN'),\n",
       " ('closing', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('think', 'VB'),\n",
       " ('could', 'MD'),\n",
       " ('close', 'VB'),\n",
       " ('like', 'IN'),\n",
       " ('brothers', 'NNS'),\n",
       " ('future', 'VBP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('air', 'NN'),\n",
       " ('feel', 'NN'),\n",
       " ('everywhere', 'RB'),\n",
       " ('Blowing', 'NNP'),\n",
       " ('wind', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('Take', 'NNP'),\n",
       " ('magic', 'NN'),\n",
       " ('moment', 'NN'),\n",
       " ('glory', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('children', 'NNS'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('dream', 'NN'),\n",
       " ('away', 'RB'),\n",
       " ('wind', 'IN'),\n",
       " ('change', 'NN'),\n",
       " ('Walking', 'NNP'),\n",
       " ('street', 'NN'),\n",
       " ('Distant', 'NNP'),\n",
       " ('memories', 'NNS'),\n",
       " ('buried', 'VBD'),\n",
       " ('past', 'JJ'),\n",
       " ('forever', 'RB'),\n",
       " ('follow', 'VBP'),\n",
       " ('Moskva', 'NNP'),\n",
       " ('Gorky', 'NNP'),\n",
       " ('Park', 'NNP'),\n",
       " ('Listening', 'NNP'),\n",
       " ('wind', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('Take', 'NNP'),\n",
       " ('magic', 'NN'),\n",
       " ('moment', 'NN'),\n",
       " ('glory', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('children', 'NNS'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('share', 'NN'),\n",
       " ('dreams', 'NNS'),\n",
       " ('Take', 'VBP'),\n",
       " ('magic', 'JJ'),\n",
       " ('moment', 'NN'),\n",
       " ('glory', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('children', 'NNS'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('dream', 'NN'),\n",
       " ('away', 'RB'),\n",
       " ('wind', 'IN'),\n",
       " ('change', 'NN'),\n",
       " ('wind', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('Blows', 'NNP'),\n",
       " ('straight', 'VBD'),\n",
       " ('face', 'NN'),\n",
       " ('time', 'NN'),\n",
       " ('Like', 'IN'),\n",
       " ('stormwind', 'NN'),\n",
       " ('ring', 'NN'),\n",
       " ('freedom', 'NN'),\n",
       " ('bell', 'VB'),\n",
       " ('peace', 'NN'),\n",
       " ('mind', 'NN'),\n",
       " ('Let', 'NNP'),\n",
       " ('balalaika', 'VB'),\n",
       " ('sing', 'VBG'),\n",
       " ('guitar', 'NN'),\n",
       " ('wants', 'VBZ'),\n",
       " ('say', 'VBP')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_pos = nltk.pos_tag(tokens)\n",
    "tokens_pos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we find it the POS of each word, we can easly extract words which belong to a particular class.\n",
    "\n",
    "For instance, let's find our the nouns and verbs in the above text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- list of nouns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Moskva', 'NNP'),\n",
       " ('Gorky', 'NNP'),\n",
       " ('Park', 'NNP'),\n",
       " ('Listening', 'NNP'),\n",
       " ('wind', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('summer', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('world', 'NN'),\n",
       " ('closing', 'NN'),\n",
       " ('brothers', 'NNS'),\n",
       " ('air', 'NN'),\n",
       " ('feel', 'NN'),\n",
       " ('Blowing', 'NNP'),\n",
       " ('wind', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('Take', 'NNP'),\n",
       " ('magic', 'NN'),\n",
       " ('moment', 'NN'),\n",
       " ('glory', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('children', 'NNS'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('dream', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('Walking', 'NNP'),\n",
       " ('street', 'NN'),\n",
       " ('Distant', 'NNP'),\n",
       " ('memories', 'NNS'),\n",
       " ('Moskva', 'NNP'),\n",
       " ('Gorky', 'NNP'),\n",
       " ('Park', 'NNP'),\n",
       " ('Listening', 'NNP'),\n",
       " ('wind', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('Take', 'NNP'),\n",
       " ('magic', 'NN'),\n",
       " ('moment', 'NN'),\n",
       " ('glory', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('children', 'NNS'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('share', 'NN'),\n",
       " ('dreams', 'NNS'),\n",
       " ('moment', 'NN'),\n",
       " ('glory', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('children', 'NNS'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('dream', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('wind', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('Blows', 'NNP'),\n",
       " ('face', 'NN'),\n",
       " ('time', 'NN'),\n",
       " ('stormwind', 'NN'),\n",
       " ('ring', 'NN'),\n",
       " ('freedom', 'NN'),\n",
       " ('peace', 'NN'),\n",
       " ('mind', 'NN'),\n",
       " ('Let', 'NNP'),\n",
       " ('guitar', 'NN')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('----------- list of nouns:')\n",
    "[e for e in tokens_pos if e[1][0] == 'N'] # loops through each element of the list which are tuples, from each tuple takes the second element which the POS, from each POS take the first letter .The POS of words that are tagged as noun always startes with 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- list of verbs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('follow', 'VB'),\n",
       " ('think', 'VB'),\n",
       " ('close', 'VB'),\n",
       " ('future', 'VBP'),\n",
       " ('buried', 'VBD'),\n",
       " ('follow', 'VBP'),\n",
       " ('Take', 'VBP'),\n",
       " ('straight', 'VBD'),\n",
       " ('bell', 'VB'),\n",
       " ('balalaika', 'VB'),\n",
       " ('sing', 'VBG'),\n",
       " ('wants', 'VBZ'),\n",
       " ('say', 'VBP')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('----------- list of verbs:')\n",
    "[e for e in tokens_pos if e[1][0] == 'V'] # loops through each element of the list which are tuples, from each tuple takes the second element which the POS, from each POS take the first letter .The POS of words that are tagged as noun always startes with 'V'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "One of valuable preprocessing step in NLP is standardizing and normalizing words to their base or root forms so that different forms of a word are treated as the same word. This technique is called lemmatization.\n",
    "\n",
    "For example, the lemma of the word \"running\" is \"run,\" and the lemma of \"better\" is \"good.\"\n",
    "\n",
    "Lemma of a word can vary depending on its grammatical role. For example, the lemma of \"better\" as an adjective is \"good,\" but as a verb, it is \"better\". Thus, lemmatization takes into account the POS of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma of the word \"better\" as an adjective: good\n",
      "lemma of the word \"better\" as a verb: better\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "print('lemma of the word \"better\" as an adjective:', lemmatizer.lemmatize(word = 'better', pos = 'a'))\n",
    "print('lemma of the word \"better\" as a verb:', lemmatizer.lemmatize(word = 'better', pos = 'v'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using above technique, let's add the lemma of the words in the 'tokens_pos' list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('follow', 'VB', 'follow'),\n",
       " ('Moskva', 'NNP', 'Moskva'),\n",
       " ('Gorky', 'NNP', 'Gorky'),\n",
       " ('Park', 'NNP', 'Park'),\n",
       " ('Listening', 'NNP', 'Listening'),\n",
       " ('wind', 'NN', 'wind'),\n",
       " ('change', 'NN', 'change'),\n",
       " ('august', 'RB', 'august'),\n",
       " ('summer', 'NN', 'summer'),\n",
       " ('night', 'NN', 'night'),\n",
       " ('world', 'NN', 'world'),\n",
       " ('closing', 'NN', 'closing'),\n",
       " ('ever', 'RB', 'ever'),\n",
       " ('think', 'VB', 'think'),\n",
       " ('could', 'MD', 'could'),\n",
       " ('close', 'VB', 'close'),\n",
       " ('like', 'IN', 'like'),\n",
       " ('brothers', 'NNS', 'brother'),\n",
       " ('future', 'VBP', 'future'),\n",
       " (\"'s\", 'POS', \"'s\"),\n",
       " ('air', 'NN', 'air'),\n",
       " ('feel', 'NN', 'feel'),\n",
       " ('everywhere', 'RB', 'everywhere'),\n",
       " ('Blowing', 'NNP', 'Blowing'),\n",
       " ('wind', 'NN', 'wind'),\n",
       " ('change', 'NN', 'change'),\n",
       " ('Take', 'NNP', 'Take'),\n",
       " ('magic', 'NN', 'magic'),\n",
       " ('moment', 'NN', 'moment'),\n",
       " ('glory', 'NN', 'glory'),\n",
       " ('night', 'NN', 'night'),\n",
       " ('children', 'NNS', 'child'),\n",
       " ('tomorrow', 'NN', 'tomorrow'),\n",
       " ('dream', 'NN', 'dream'),\n",
       " ('away', 'RB', 'away'),\n",
       " ('wind', 'IN', 'wind'),\n",
       " ('change', 'NN', 'change'),\n",
       " ('Walking', 'NNP', 'Walking'),\n",
       " ('street', 'NN', 'street'),\n",
       " ('Distant', 'NNP', 'Distant'),\n",
       " ('memories', 'NNS', 'memory'),\n",
       " ('buried', 'VBD', 'bury'),\n",
       " ('past', 'JJ', 'past'),\n",
       " ('forever', 'RB', 'forever'),\n",
       " ('follow', 'VBP', 'follow'),\n",
       " ('Moskva', 'NNP', 'Moskva'),\n",
       " ('Gorky', 'NNP', 'Gorky'),\n",
       " ('Park', 'NNP', 'Park'),\n",
       " ('Listening', 'NNP', 'Listening'),\n",
       " ('wind', 'NN', 'wind'),\n",
       " ('change', 'NN', 'change'),\n",
       " ('Take', 'NNP', 'Take'),\n",
       " ('magic', 'NN', 'magic'),\n",
       " ('moment', 'NN', 'moment'),\n",
       " ('glory', 'NN', 'glory'),\n",
       " ('night', 'NN', 'night'),\n",
       " ('children', 'NNS', 'child'),\n",
       " ('tomorrow', 'NN', 'tomorrow'),\n",
       " ('share', 'NN', 'share'),\n",
       " ('dreams', 'NNS', 'dream'),\n",
       " ('Take', 'VBP', 'Take'),\n",
       " ('magic', 'JJ', 'magic'),\n",
       " ('moment', 'NN', 'moment'),\n",
       " ('glory', 'NN', 'glory'),\n",
       " ('night', 'NN', 'night'),\n",
       " ('children', 'NNS', 'child'),\n",
       " ('tomorrow', 'NN', 'tomorrow'),\n",
       " ('dream', 'NN', 'dream'),\n",
       " ('away', 'RB', 'away'),\n",
       " ('wind', 'IN', 'wind'),\n",
       " ('change', 'NN', 'change'),\n",
       " ('wind', 'NN', 'wind'),\n",
       " ('change', 'NN', 'change'),\n",
       " ('Blows', 'NNP', 'Blows'),\n",
       " ('straight', 'VBD', 'straight'),\n",
       " ('face', 'NN', 'face'),\n",
       " ('time', 'NN', 'time'),\n",
       " ('Like', 'IN', 'Like'),\n",
       " ('stormwind', 'NN', 'stormwind'),\n",
       " ('ring', 'NN', 'ring'),\n",
       " ('freedom', 'NN', 'freedom'),\n",
       " ('bell', 'VB', 'bell'),\n",
       " ('peace', 'NN', 'peace'),\n",
       " ('mind', 'NN', 'mind'),\n",
       " ('Let', 'NNP', 'Let'),\n",
       " ('balalaika', 'VB', 'balalaika'),\n",
       " ('sing', 'VBG', 'sing'),\n",
       " ('guitar', 'NN', 'guitar'),\n",
       " ('wants', 'VBZ', 'want'),\n",
       " ('say', 'VBP', 'say')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we use the 'WordNetLemmatizer()', we need to create a helper function to map the POS tags in our list with the WordNet's POS tagset.\n",
    "# It's important to note that POS tagging can be context-dependent and challenging.\n",
    "# For example, foreign words (words that are tagged as FW) may function as nouns, but they can also function as other parts of speech depending on the context.\n",
    "# Thus, you can adjust the helper function based on different context\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos):\n",
    "    if pos.startswith('J'): return wordnet.ADJ # Adjective\n",
    "    elif pos.startswith('V'): return wordnet.VERB # Verb\n",
    "    elif pos.startswith('N'): return wordnet.NOUN # Noun\n",
    "    elif pos.startswith('R'): return wordnet.ADV # Adverb\n",
    "    elif pos.startswith('D'): return wordnet.ADJ_SAT  # Adverbs\n",
    "    elif pos.startswith('P'): return wordnet.ADJ_SAT  # Pronouns\n",
    "    elif pos.startswith('C'): return wordnet.ADJ_SAT  # Conjunctions\n",
    "    elif pos.startswith('U'): return wordnet.ADJ_SAT  # Interjections\n",
    "    elif pos.startswith('M'): return wordnet.ADJ_SAT  # Modals\n",
    "    elif pos == 'CC': return wordnet.ADV  # Coordinating conjunctions\n",
    "    elif pos == 'DT': return wordnet.ADJ_SAT  # Determiners\n",
    "    elif pos == 'IN': return wordnet.ADJ_SAT  # Prepositions\n",
    "    elif pos == 'TO': return wordnet.ADJ_SAT  # 'to' as part of infinitive verb\n",
    "    elif pos == 'MD': return wordnet.ADJ_SAT  # Modal verbs\n",
    "    elif pos == 'EX': return wordnet.ADV  # Existential 'there'\n",
    "    elif pos == 'CD': return wordnet.NOUN  # Cardinal numbers\n",
    "    elif pos == 'UH': return wordnet.INTJ  # Interjections\n",
    "    else: return wordnet.NOUN  # Default to noun if no specific mapping\n",
    "\n",
    "tokens_pos_lemma = [(word, pos, lemmatizer.lemmatize(word,  get_wordnet_pos(pos))) for word, pos in tokens_pos]\n",
    "tokens_pos_lemma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this moment, the list of words has the words as they are found in the text, their POS, and the base / root form of each word.\n",
    "Let's find if a word in the text is different than its base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in the text: brothers\n",
      "POS tagging: NNS\n",
      "Base or root form brother\n",
      "--------------------------\n",
      "Found in the text: children\n",
      "POS tagging: NNS\n",
      "Base or root form child\n",
      "--------------------------\n",
      "Found in the text: memories\n",
      "POS tagging: NNS\n",
      "Base or root form memory\n",
      "--------------------------\n",
      "Found in the text: buried\n",
      "POS tagging: VBD\n",
      "Base or root form bury\n",
      "--------------------------\n",
      "Found in the text: children\n",
      "POS tagging: NNS\n",
      "Base or root form child\n",
      "--------------------------\n",
      "Found in the text: dreams\n",
      "POS tagging: NNS\n",
      "Base or root form dream\n",
      "--------------------------\n",
      "Found in the text: children\n",
      "POS tagging: NNS\n",
      "Base or root form child\n",
      "--------------------------\n",
      "Found in the text: wants\n",
      "POS tagging: VBZ\n",
      "Base or root form want\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for word, pos, lemma in tokens_pos_lemma:\n",
    "    if word != lemma:\n",
    "        print('Found in the text:', word)\n",
    "        print('POS tagging:', pos)\n",
    "        print('Base or root form', lemma)\n",
    "        print('--------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
