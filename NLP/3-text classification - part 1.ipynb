{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "\n",
    "### Part 1) Similarity analysis\n",
    "\n",
    "Below are 3 different texts. Calculate the level similarity between them and find out which of the texts are more similar to each other.\n",
    "\n",
    "steps:\n",
    "\n",
    "        - create the feature vector of each text\n",
    "\n",
    "        - make all vectors compareable. it means that the same position in each vector should represent the same word\n",
    "                \n",
    "        To achieve this we have to:\n",
    "                - create a unified vocabulary from the feature vectors\n",
    "                - recreate the feature vectors ensuring that each position in the vectors represents the same word\n",
    "\n",
    "Feature vector is a numerical representation a text. i.e., frequencies of a set of features/words in a text. This type of vector representation is commonly used for tasks like text classification, clustering, or similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"The Jaccard coefficient or Jaccard index, also known as Intersection over Union, named after the Swiss botanist Paul Jaccard (1868–1944), is a measure of the similarity of sets. It is often referred to by its definition as IoU (Intersection over Union).\"\n",
    "text2 = \"The Isabelline Ghost Bat (Diclidurus isabella or Diclidurus isabellus) is a bat species found in northern South America, belonging to the genus of American Ghost Bats. This species is the only representative of the subgenus Depanycteris, which was temporarily classified as a separate genus. Despite the isabelline-colored body parts, Oldfield Thomas may have referred to a person named Isabell in his initial description.\"\n",
    "text3  = \"The American Ghost Bats (Diclidurus) are a genus of bats from the family of Smooth-tailed Free-tailed Bats. Along with the White Bat, they are among the only bats that are light gray to white in color. They are native to the tropical regions of Central and South America.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_vec1 ----------: 23\n",
      "Counter({'Jaccard': 3, ',': 3, 'Intersection': 2, 'Union': 2, '(': 2, ')': 2, '.': 2, 'coefficient': 1, 'index': 1, 'also': 1, 'known': 1, 'named': 1, 'Swiss': 1, 'botanist': 1, 'Paul': 1, '1868–1944': 1, 'measure': 1, 'similarity': 1, 'sets': 1, 'often': 1, 'referred': 1, 'definition': 1, 'IoU': 1})\n",
      "feature_vec2 ----------: 39\n",
      "Counter({',': 3, '.': 3, 'Ghost': 2, 'Diclidurus': 2, 'species': 2, 'genus': 2, 'Isabelline': 1, 'Bat': 1, '(': 1, 'isabella': 1, 'isabellus': 1, ')': 1, 'bat': 1, 'found': 1, 'northern': 1, 'South': 1, 'America': 1, 'belonging': 1, 'American': 1, 'Bats': 1, 'representative': 1, 'subgenus': 1, 'Depanycteris': 1, 'temporarily': 1, 'classified': 1, 'separate': 1, 'Despite': 1, 'isabelline-colored': 1, 'body': 1, 'parts': 1, 'Oldfield': 1, 'Thomas': 1, 'may': 1, 'referred': 1, 'person': 1, 'named': 1, 'Isabell': 1, 'initial': 1, 'description': 1})\n",
      "feature_vec3 ----------: 27\n",
      "Counter({'.': 3, 'Bats': 2, 'bats': 2, 'American': 1, 'Ghost': 1, '(': 1, 'Diclidurus': 1, ')': 1, 'genus': 1, 'family': 1, 'Smooth-tailed': 1, 'Free-tailed': 1, 'Along': 1, 'White': 1, 'Bat': 1, ',': 1, 'among': 1, 'light': 1, 'gray': 1, 'white': 1, 'color': 1, 'native': 1, 'tropical': 1, 'regions': 1, 'Central': 1, 'South': 1, 'America': 1})\n"
     ]
    }
   ],
   "source": [
    "# creating feature vector - frequencies of individual words or tokens\n",
    "\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def count_text(text):\n",
    "    tokens = nltk.word_tokenize(text, language='english') # tokenize the text\n",
    "    tokens = [e for e in tokens if e.lower() not in stopwords] # remove stopwords and punctuations\n",
    "\n",
    "    return Counter(tokens)\n",
    "\n",
    "feature_vec1 = count_text(text1)\n",
    "feature_vec2 = count_text(text2)\n",
    "feature_vec3 = count_text(text3)\n",
    "\n",
    "print('feature_vec1 ----------:', len(feature_vec1))\n",
    "print(feature_vec1)\n",
    "\n",
    "print('feature_vec2 ----------:', len(feature_vec2))\n",
    "print(feature_vec2)\n",
    "\n",
    "print('feature_vec3 ----------:', len(feature_vec3))\n",
    "print(feature_vec3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary ----------: 71\n",
      "{'body', 'native', 'family', 'Oldfield', 'Thomas', 'person', '1868–1944', 'Isabell', 'South', 'separate', 'American', 'Intersection', 'definition', 'index', 'Isabelline', 'Depanycteris', 'White', 'among', 'description', 'known', 'referred', 'northern', 'sets', ')', 'botanist', 'Bats', 'Central', 'bat', 'representative', '(', 'also', '.', 'Free-tailed', 'IoU', 'coefficient', 'temporarily', 'bats', 'color', 'Smooth-tailed', 'similarity', 'gray', 'Ghost', 'classified', 'named', 'found', 'species', 'isabelline-colored', 'Union', 'tropical', 'subgenus', 'Jaccard', 'Paul', 'Bat', 'Diclidurus', 'Along', 'regions', 'isabellus', 'may', 'belonging', 'initial', 'light', 'white', 'Swiss', 'America', 'isabella', ',', 'measure', 'often', 'parts', 'Despite', 'genus'}\n",
      "feature_vec1 ----------: 71\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0, 2, 1, 2, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 1, 1, 0, 0, 0]\n",
      "feature_vec2 ----------: 71\n",
      "[1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 1, 1, 2, 1, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 3, 0, 0, 1, 1, 2]\n",
      "feature_vec3 ----------: 71\n",
      "[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 3, 1, 0, 0, 0, 2, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# make all vectors compareable\n",
    "vocabulary=[]\n",
    "\n",
    "for feature in [feature_vec1, feature_vec2, feature_vec3]:\n",
    "    for word in feature:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = set(vocabulary)\n",
    "print('vocabulary ----------:', len(vocabulary))\n",
    "print(vocabulary)\n",
    "\n",
    "feature_vec1_values = [feature_vec1.get(word, 0) for word in vocabulary]\n",
    "feature_vec2_values = [feature_vec2.get(word, 0) for word in vocabulary]\n",
    "feature_vec3_values = [feature_vec3.get(word, 0) for word in vocabulary]\n",
    "\n",
    "print('feature_vec1 ----------:', len(feature_vec1_values))\n",
    "print(feature_vec1_values)\n",
    "\n",
    "print('feature_vec2 ----------:', len(feature_vec2_values))\n",
    "print(feature_vec2_values)\n",
    "\n",
    "print('feature_vec3 ----------:', len(feature_vec3_values))\n",
    "print(feature_vec3_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all feature vectors are compareable, we can do similary analysis using, but not limited to, below method.\n",
    "\n",
    "#### a) Jaccard coefficient\n",
    "Jaccard coefficient is simplest way to measure how similar two texts are. It counts the number of words that are common between the texts and divides it by the total number of unique words in both texts.\n",
    "\n",
    "            jac(A, B) = |A ∩ B| / |A ∪ B|\n",
    "\n",
    "It produces values between 0 and 1, where 1 indicates perfect similarity and 0 indicates no similarity.\n",
    "\n",
    "#### b) Manhattan distance metric\n",
    "Unlike Jaccard coeficient, manhattan distance does not consider if a word is common between two texts, but it also takes into account the number of times a word is mentioned in each text.\n",
    "\n",
    "                Manhattan Distance(A, B) = Σ |Ai - Bi| for i=1 to n\n",
    "                        - Ai and Bi are the frequencies of each word in the texts / feature vectors\n",
    "                        - n is the total number of features/words\n",
    "\n",
    "Manhattan distance metric produces non-negative integer values, where 0 indicates perfect similarity and higher values suggest increasing dissimilarity.\n",
    "\n",
    "#### c) Cosine similarity\n",
    "Manhattan distance is largely affected by the length of the text. To overcome this, Cosine similarity introduces another way to measure the text similarity as below.\n",
    "\n",
    "        cos (A,B) = Σi Ai·Bi / √Σi A^2i · √Σi B^2i\n",
    "            \n",
    "Cosine similarity is beneficial when you want to focus on the semantic similarity between texts because it's not sensitive to the text's length.\n",
    "\n",
    "It produces values between -1 and 1, where 1 indicates perfect similarity and -1 indicates perfect dissimilarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard coefficient between text1, text2, and text3\n",
    "def jaccard(vector1, vector2):\n",
    "    interc=0\n",
    "    union=0\n",
    "    for i in range(len(vector1)):\n",
    "        if vector1[i]>0 and vector2[i]>0:\n",
    "            interc+=1\n",
    "        elif vector1[i]>0 or vector2[i]>0:\n",
    "            union+=1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return interc/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard coefficient between text1 and text2 = 0.12\n",
      "Jaccard coefficient between text1 and text3 = 0.09523809523809523\n",
      "Jaccard coefficient between text2 and text3 = 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "jac_text1_vs_text2 = jaccard(feature_vec1_values, feature_vec2_values)\n",
    "jac_text1_vs_text3 = jaccard(feature_vec1_values, feature_vec3_values)\n",
    "jac_text2_vs_text3 = jaccard(feature_vec2_values, feature_vec3_values)\n",
    "\n",
    "print('Jaccard coefficient between text1 and text2 =', jac_text1_vs_text2)\n",
    "print('Jaccard coefficient between text1 and text3 =', jac_text1_vs_text3)\n",
    "print('Jaccard coefficient between text2 and text3 =', jac_text2_vs_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance between text1 and text2 = 61\n",
      "Manhattan distance between text1 and text3 = 53\n",
      "Manhattan distance between text2 and text3 = 50\n"
     ]
    }
   ],
   "source": [
    "# Manhattan distance between text1, text2, and text3\n",
    "manhattan_text1_text2 = sum([abs(v1-v2) for v1, v2 in zip(feature_vec1_values, feature_vec2_values)])\n",
    "manhattan_text1_text3 = sum([abs(v1-v2) for v1, v2 in zip(feature_vec1_values, feature_vec3_values)])\n",
    "manhattan_text2_text3 = sum([abs(v1-v2) for v1, v2 in zip(feature_vec2_values, feature_vec3_values)])\n",
    "\n",
    "print('Manhattan distance between text1 and text2 =', manhattan_text1_text2)\n",
    "print('Manhattan distance between text1 and text3 =', manhattan_text1_text3)\n",
    "print('Manhattan distance between text2 and text3 =', manhattan_text2_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between text1 and text2 = 0.3491282676376715\n",
      "Cosine similarity between text1 and text3 = 0.27628324232744655\n",
      "Cosine similarity between text2 and text3 = 0.4960712045370879\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity between text1, text2, and text3\n",
    "import math\n",
    "\n",
    "def cosine(vector1, vector2):\n",
    "    aibi = sum([v1*v2 for v1, v2 in zip(vector1, vector2)])\n",
    "    sqrt_ai2 = math.sqrt(sum([v**2 for v in vector1]))\n",
    "    sqrt_bi2 = math.sqrt(sum([v**2 for v in vector2]))  \n",
    "\n",
    "    return (aibi) / (sqrt_ai2 * sqrt_bi2)\n",
    "\n",
    "cosine_text1_text2 = cosine(feature_vec1_values, feature_vec2_values)\n",
    "cosine_text1_text3 = cosine(feature_vec1_values, feature_vec3_values)\n",
    "cosine_text2_text3 = cosine(feature_vec2_values, feature_vec3_values)\n",
    "\n",
    "print('Cosine similarity between text1 and text2 =', cosine_text1_text2)\n",
    "print('Cosine similarity between text1 and text3 =', cosine_text1_text3)\n",
    "print('Cosine similarity between text2 and text3 =', cosine_text2_text3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, text-2 and text-3 are more similar (Jaccard coefficient = 2.89, Manhattan distance = 50, Cosine similarity = 0.5) than text-1 and text2 (Jaccard coefficient = 0.12, Manhattan distance = 61, Cosine similarity = 0.35) or text-1 and text-3 (Jaccard coefficient = 0.095, Manhattan distance = 53, Cosine similarity = 0.28)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "            Note to self. All in one:\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import math\n",
    "\n",
    "def simalarity(text1, text2, type = 'Jaccard', remove_stop_words = True, language = 'english'):\n",
    "\n",
    "    # create feature vectors\n",
    "    text1_tokens = nltk.word_tokenize(text1, language=language)\n",
    "    text2_tokens = nltk.word_tokenize(text2, language=language)\n",
    "\n",
    "    if remove_stop_words:\n",
    "        stopwords = nltk.corpus.stopwords.words(language)\n",
    "        text1_tokens = [e for e in text1_tokens if e.lower() not in stopwords]\n",
    "        text2_tokens = [e for e in text2_tokens if e.lower() not in stopwords]\n",
    "\n",
    "    feature_vec1 = Counter(text1_tokens)\n",
    "    feature_vec2 = Counter(text2_tokens)\n",
    "\n",
    "    # make feature vectors comparable / normalize\n",
    "    vocabulary=[]\n",
    "    for feature in [feature_vec1, feature_vec2]:\n",
    "        for word in feature:\n",
    "            vocabulary.append(word)\n",
    "    vocabulary = set(vocabulary)\n",
    "    feature_vec1_values = [feature_vec1.get(word, 0) for word in vocabulary]\n",
    "    feature_vec2_values = [feature_vec2.get(word, 0) for word in vocabulary]\n",
    "\n",
    "    # similarity analysis \n",
    "    if type == 'Jaccard':\n",
    "            interc=0\n",
    "            union=0\n",
    "            for i in range(len(feature_vec1_values)):\n",
    "                if feature_vec1_values[i]>0 and feature_vec2_values[i]>0:\n",
    "                    interc+=1\n",
    "                elif feature_vec1_values[i]>0 or feature_vec2_values[i]>0:\n",
    "                    union+=1\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            return interc/union\n",
    "    \n",
    "    elif type == 'Manhattan':\n",
    "        return sum([abs(v1-v2) for v1, v2 in zip(feature_vec1_values, feature_vec2_values)])\n",
    "\n",
    "    elif type == \"Cosine\":\n",
    "        aibi = sum([v1*v2 for v1, v2 in zip(feature_vec1_values, feature_vec2_values)])\n",
    "        sqrt_ai2 = math.sqrt(sum([v**2 for v in feature_vec1_values]))\n",
    "        sqrt_bi2 = math.sqrt(sum([v**2 for v in feature_vec2_values]))\n",
    "\n",
    "        return (aibi) / (sqrt_ai2 * sqrt_bi2)\n",
    "    \n",
    "    else:\n",
    "        return 'Please make sure you selected the correct type for similarity analysis.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12\n",
      "0.09523809523809523\n",
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "t = 'Jaccard'\n",
    "print(simalarity(text1, text2, type = t))\n",
    "print(simalarity(text1, text3, type = t))\n",
    "print(simalarity(text2, text3, type = t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "53\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "t = 'Manhattan'\n",
    "print(simalarity(text1, text2, type = t))\n",
    "print(simalarity(text1, text3, type = t))\n",
    "print(simalarity(text2, text3, type = t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3491282676376715\n",
      "0.27628324232744655\n",
      "0.4960712045370879\n"
     ]
    }
   ],
   "source": [
    "t = 'Cosine'\n",
    "print(simalarity(text1, text2, type = t))\n",
    "print(simalarity(text1, text3, type = t))\n",
    "print(simalarity(text2, text3, type = t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure you selected the correct type for similarity analysis.\n",
      "Please make sure you selected the correct type for similarity analysis.\n",
      "Please make sure you selected the correct type for similarity analysis.\n"
     ]
    }
   ],
   "source": [
    "t = 'xyz',\n",
    "print(simalarity(text1, text2, type = t))\n",
    "print(simalarity(text1, text3, type = t))\n",
    "print(simalarity(text2, text3, type = t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
